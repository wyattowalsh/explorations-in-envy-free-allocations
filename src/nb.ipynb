{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> IEOR 169 Final Project: Data Generation and Exploration </center>\n",
    "# <center> Team: Chris Landgrebe, Calvin Suster, Wyatt Walsh </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Generation\" data-toc-modified-id=\"Data-Generation-1\">Data Generation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-1:-Imports-and-Environment-Considerations\" data-toc-modified-id=\"Step-1:-Imports-and-Environment-Considerations-1.1\">Step 1: Imports and Environment Considerations</a></span></li><li><span><a href=\"#Step-2:-Define-Generator-Function\" data-toc-modified-id=\"Step-2:-Define-Generator-Function-1.2\">Step 2: Define Generator Function</a></span></li><li><span><a href=\"#Step-3:-Define-Set-of-Person/Object-Combinations-and-Apply-Generator\" data-toc-modified-id=\"Step-3:-Define-Set-of-Person/Object-Combinations-and-Apply-Generator-1.3\">Step 3: Define Set of Person/Object Combinations and Apply Generator</a></span></li><li><span><a href=\"#Step-1:-Load-in-Data-and-View\" data-toc-modified-id=\"Step-1:-Load-in-Data-and-View-1.4\">Step 1: Load in Data and View</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Imports and Environment Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T08:04:29.674683Z",
     "start_time": "2020-05-01T08:04:27.907609Z"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define Generator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0 .. 0.25 by 0.00625) union (0.4 .. 1 by 0.3);\n",
    "param cash;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T08:06:39.900647Z",
     "start_time": "2020-05-01T08:06:39.895100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.     , 0.00625, 0.0125 , 0.01875, 0.025  , 0.03125, 0.0375 ,\n",
       "       0.04375, 0.05   , 0.05625, 0.0625 , 0.06875, 0.075  , 0.08125,\n",
       "       0.0875 , 0.09375, 0.1    , 0.10625, 0.1125 , 0.11875, 0.125  ,\n",
       "       0.13125, 0.1375 , 0.14375, 0.15   , 0.15625, 0.1625 , 0.16875,\n",
       "       0.175  , 0.18125, 0.1875 , 0.19375, 0.2    , 0.20625, 0.2125 ,\n",
       "       0.21875, 0.225  , 0.23125, 0.2375 , 0.24375, 0.25   , 0.4    ,\n",
       "       0.6    , 0.8    , 1.     ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(np.arange(0,0.25+0.00624,0.00625), np.arange(0.4,1.1,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [1,4,5]\n",
    "grid = np.random.uniform(0,1,(sizes[1:]))\n",
    "normed = np.round(grid/np.sum(grid,1)[:,None],4)\n",
    "df = pd.DataFrame(normed)\n",
    "df\n",
    "df.to_csv('./data/generated/prologtest.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize(sizes):\n",
    "    '''This function takes in row of a dataframe that contains three columns:\n",
    "    1. the index associated with that row'\n",
    "    2. the number of objects for this particular dataset\n",
    "    3. the number of people for this particular dataset\n",
    "    These parameters are then used to generate a matrix of Uniform[0,1] r.v.s of whic is then massaged into\n",
    "    a compatible .dat format for use in AMPL'''\n",
    "    \n",
    "    # create r.v. matrix of size len(people) by len(objects) then normalize\n",
    "    ## normalization in this case takes the form of dividing rows by their respective sums\n",
    "    grid = np.random.uniform(0,1,(sizes[1:]))\n",
    "    normed = grid/np.sum(grid,1)[:,None]\n",
    "    \n",
    "    # create df with columns whose values correspond with the indice of the value from the original matrix\n",
    "    df = pd.DataFrame(normed).reset_index()\n",
    "\n",
    "    # add 1 to all variables so that the ranges start from 1\n",
    "    df.iloc[:,0] = df.iloc[:,0].astype('int32') + 1\n",
    "    \n",
    "    # move columns for correct AMPL reading\n",
    "    columns = ['p', *range(1,sizes[2]+1)]\n",
    "    df.columns = columns \n",
    "    \n",
    "    # get index of current row for use in file naming\n",
    "    name = './data/generated/' +  str(sizes[0]) + '.dat'\n",
    "    # generate the sets for people and objects given their size\n",
    "    people = ' '.join([str(i) for i in range(1,sizes[1]+1)])\n",
    "    items = ' '.join([str(i) for i in range(1,sizes[2]+1)])\n",
    "    \n",
    "    # since np.savetxt will be used, bundle all other information in the header\n",
    "    header = 'data; \\nset P := %s; \\n' % people\n",
    "    header += 'set I := %s;' % items\n",
    "    header += '\\nparam v : '\n",
    "    header += items + ':='\n",
    "    \n",
    "    types = ['%i'] + (['%.4f'] * sizes[2])\n",
    "    # save df values space separated under header\n",
    "    np.savetxt(name, df.values, fmt = types, header = header, comments = '')\n",
    "    # add final semicolon and close file\n",
    "    file = open(name, 'a')\n",
    "    file.write('\\n ;')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detCash(cash, numItem):\n",
    "    num = np.matrix([0.5]+[0]*(numItem-1))\n",
    "    row_sum = np.array([sum(num)])\n",
    "    for i in range(1,numItem):\n",
    "        num = np.append(num, np.matrix([0.5]*(i+1) + (numItem-i-1) * [0]),0)\n",
    "\n",
    "    # row_sum = sum(num)\n",
    "    # num = num/row_sum\n",
    "    # sum(num)\n",
    "    # num = np.append(num,1)\n",
    "    # num = num/(1+5)\n",
    "    # sum(num)\n",
    "# #     display(pd.DataFrame(num))\n",
    "\n",
    "    normed = num/np.sum(num,1)\n",
    "    display(pd.DataFrame(normed))\n",
    "\n",
    "    add = np.matrix([cash] * numItem).T\n",
    "    normed = np.append(normed,add,1)/(np.sum(normed,1) + cash)\n",
    "    # # normed = np.append(normed,add,0)/(sum(normed,1) + 1)\n",
    "    display(pd.DataFrame(normed))\n",
    "# #     display(pd.DataFrame(np.sum(normed,1)).T)\n",
    "#     display(np.shape(normed))\n",
    "\n",
    "for c in cash:\n",
    "    detCash(c,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_cash(sizes):\n",
    "    '''This function takes in row of a dataframe that contains three columns:\n",
    "    1. the index associated with that row'\n",
    "    2. the number of objects for this particular dataset\n",
    "    3. the number of people for this particular dataset\n",
    "    These parameters are then used to generate a matrix of Uniform[0,1] r.v.s of whic is then massaged into\n",
    "    a compatible .dat format for use in AMPL'''\n",
    "    \n",
    "    # set random seed for reproducibility\n",
    "    # create r.v. matrix of size len(people) by len(objects) then normalize\n",
    "    ## normalization in this case takes the form of dividing rows by their respective sums\n",
    "    grid = np.random.uniform(0,1,(sizes[1:]))\n",
    "    \n",
    "    # create df with columns whose values correspond with the indice of the value from the original matrix\n",
    "    df = pd.DataFrame(grid).reset_index()\n",
    "    \n",
    "    # add 1 to all variables so that the ranges start from 1\n",
    "    df.iloc[:,0] = df.iloc[:,0].astype('int32') + 1\n",
    "    \n",
    "    # move columns for correct AMPL reading\n",
    "    columns = ['p', *range(1,sizes[2]+1)]\n",
    "    df.columns = columns \n",
    "    \n",
    "    # get index of current row for use in file naming\n",
    "    name = './data/generated/' +  str(sizes[0]) + '_' + ;cash.dat'\n",
    "    # generate the sets for people and objects given their size\n",
    "    people = ' '.join([str(i) for i in range(1,sizes[1]+1)])\n",
    "    items = ' '.join([str(i) for i in range(1,sizes[2]+1)])\n",
    "    \n",
    "    # since np.savetxt will be used, bundle all other information in the header\n",
    "    header = 'data; \\nset P := %s; \\n' % people\n",
    "    header += 'set I := %s;' % items\n",
    "    header += '\\nparam v : '\n",
    "    header += items + ':='\n",
    "    \n",
    "    types = ['%i'] + (['%.4f'] * sizes[2])\n",
    "    # save df values space separated under header\n",
    "    np.savetxt(name, df.values, fmt = types, header = header, comments = '')\n",
    "    # add final semicolon and close file\n",
    "    file = open(name, 'a')\n",
    "    file.write('\\n ;')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define Set of Person/Object Combinations and Apply Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define range of values to combine\n",
    "## linear spacing is utilized until 160, then a log spacing is used since order of magnitude is more important\n",
    "# values = np.append(np.array([5,10,20,40,80,160]), np.geomspace(320, 5120, 14, dtype = int))\n",
    "values = [*range(5,15), *range(15,25,5), *range(25,150,25), *range(150,250,100), *range(250, 1001, 250), *range(1000, 5001, 2000), 10000]\n",
    "\n",
    "# create df from meshed value ranges.\n",
    "# ## must take transpose of meshgrid and reshape in order for output to be .dat file ready\n",
    "sizes = pd.DataFrame(np.array(np.meshgrid(values,values)).T.reshape(-1,2))\n",
    "\n",
    "# # remove any rows where there are more people than objects since min p will always be 1\n",
    "sizes = sizes.loc[sizes[1] <= sizes[0] * 4].reset_index(drop=True).reset_index()\n",
    "columns = ['fileNum', 'numPeople', 'numItems']\n",
    "sizes.columns = columns\n",
    "\n",
    "# # add 1 to index so that row sets start at 1 and display resultant df\n",
    "sizes['fileNum'] = sizes['fileNum'] + 1\n",
    "display(sizes)\n",
    "\n",
    "# # apply generator function to remaining rows \n",
    "sizes.apply(synthesize, axis = 1) # !!! line 17 is commmented out since the data already exists !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "400*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([*np.arange(0,0.26,0.0125), *np.arange(0.4,1,0.3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load in Data and View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/output/full.txt')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0125/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T21:15:47.517829Z",
     "start_time": "2020-04-30T21:15:47.488624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display\n",
    "from math import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import importlib\n",
    "\n",
    "import agent_based_simulation\n",
    "from agent_based_simulation import agent, functions\n",
    "agent_based_simulation = importlib.reload(agent_based_simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T21:15:47.879893Z",
     "start_time": "2020-04-30T21:15:47.852711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  0.4  0.1\n",
       "1  0.6  0.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple = np.array([[0.4,0.1],[0.6,0.2]])\n",
    "display(pd.DataFrame(simple))\n",
    "(num_agents, num_items) = simple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T21:15:48.793772Z",
     "start_time": "2020-04-30T21:15:48.770027Z"
    }
   },
   "outputs": [],
   "source": [
    "agents = []\n",
    "for i in np.arange(0,num_agents):\n",
    "    agents.append(agent.Agent(i,simple[i]))\n",
    "    \n",
    "functions.first_allocation(agents,np.arange(num_items))\n",
    "functions.share(agents)\n",
    "functions.calculate_p_envy_free(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T21:16:17.444170Z",
     "start_time": "2020-04-30T21:16:17.413369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T21:04:35.562574Z",
     "start_time": "2020-04-30T21:04:35.536307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(agent.portfolio) for agent in agents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T20:03:04.806653Z",
     "start_time": "2020-04-30T20:03:04.779429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8 , 0.2 ],\n",
       "       [0.75, 0.25]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T20:28:46.036439Z",
     "start_time": "2020-04-30T20:28:46.015779Z"
    }
   },
   "outputs": [],
   "source": [
    "portfolio = []\n",
    "portfolio = portfolio.append(5)\n",
    "portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
